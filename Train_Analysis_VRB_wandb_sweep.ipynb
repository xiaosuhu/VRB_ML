{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "WANDB_NOTEBOOK_NAME = 'Train_Analysis_VRB_wandb_sweep.ipynb'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 87ggx27m\n",
      "Sweep URL: https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\n"
     ]
    }
   ],
   "source": [
    "config={\n",
    "    'batch_size':64,\n",
    "    'lr':0.0001,\n",
    "    'epochs':5\n",
    "}\n",
    "\n",
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [32]},\n",
    "        'epochs': {'values': [5]},\n",
    "        'lr': {'values': [0.001, 0.0001]}\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='VRB-Pytorch-test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNIRS_Dataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.targets = self.img_labels['Label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 4])\n",
    "        image = np.float32(io.loadmat(img_path)['fnirsimg']).reshape(3,21,45)\n",
    "        label = self.img_labels.iloc[idx, 5]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        classifications = torch.argmax(model(X), dim=1)\n",
    "        correct_predictions = sum(classifications==y).item()\n",
    "\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(y)\n",
    "            \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"val_loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    acc = total_correct/total_instances\n",
    "    print(f\"val_acc: {acc:>7f}\")\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w3bxo0zt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004591429675591624\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/frank/Applications/MATLAB/PROJECT_VRB/Pytorch/wandb/run-20230411_155443-w3bxo0zt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/w3bxo0zt\" target=\"_blank\">valiant-sweep-4</a></strong> to <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/w3bxo0zt\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/w3bxo0zt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c731c0aa2d94ea19b31e32afa0de3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">valiant-sweep-4</strong> at: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/w3bxo0zt\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/w3bxo0zt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_155443-w3bxo0zt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run w3bxo0zt errored: FileNotFoundError(2, 'No such file or directory')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run w3bxo0zt errored: FileNotFoundError(2, 'No such file or directory')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e56rf8ai with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.006395440690108898\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/frank/Applications/MATLAB/PROJECT_VRB/Pytorch/wandb/run-20230411_155455-e56rf8ai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/e56rf8ai\" target=\"_blank\">volcanic-sweep-5</a></strong> to <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/e56rf8ai\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/e56rf8ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-sweep-5</strong> at: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/e56rf8ai\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/e56rf8ai</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_155455-e56rf8ai/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run e56rf8ai errored: FileNotFoundError(2, 'No such file or directory')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run e56rf8ai errored: FileNotFoundError(2, 'No such file or directory')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2q14eqxc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001617613911461978\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/frank/Applications/MATLAB/PROJECT_VRB/Pytorch/wandb/run-20230411_155506-2q14eqxc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/2q14eqxc\" target=\"_blank\">azure-sweep-6</a></strong> to <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/87ggx27m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/2q14eqxc\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/2q14eqxc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-sweep-6</strong> at: <a href=\"https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/2q14eqxc\" target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/2q14eqxc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230411_155506-2q14eqxc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 2q14eqxc errored: FileNotFoundError(2, 'No such file or directory')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 2q14eqxc errored: FileNotFoundError(2, 'No such file or directory')\n",
      "Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"
     ]
    }
   ],
   "source": [
    "# Load the data with imbalanced weights\n",
    "train_data=FNIRS_Dataset(\n",
    "    '../Label_VRB.csv',\n",
    "    '../VRBdata/'\n",
    ")\n",
    "\n",
    "total_targets=torch.asarray(train_data.targets)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "    np.arange(len(total_targets)), test_size=0.2, random_state=42, shuffle=True, stratify=total_targets)\n",
    "\n",
    "train_set = torch.utils.data.Subset(train_data, train_idx)\n",
    "# val_set = torch.utils.data.Subset(train_data, valid_idx)\n",
    "\n",
    "train_sample_count = torch.tensor(\n",
    "    [(total_targets[train_idx] == t).sum() for t in torch.unique(total_targets, sorted=True)])\n",
    "train_weight = 1. / train_sample_count.float()\n",
    "train_sample_weight = torch.tensor([train_weight[t] for t in total_targets[train_idx]])\n",
    "\n",
    "#Creating PT data samplers\n",
    "train_sampler = WeightedRandomSampler(train_sample_weight, len(train_sample_weight))\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "def main():\n",
    "    run = wandb.init()\n",
    "\n",
    "    batch_size = wandb.config.batch_size\n",
    "\n",
    "    # Create data loaders:\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
    "                                            sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "    # Model defining\n",
    "    model = timm.create_model('legacy_seresnet18', num_classes=2, pretrained=False)\n",
    "    model=model.to(device)\n",
    "    \n",
    "    # Other learning parameters\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.lr)\n",
    "    epochs = wandb.config.epochs\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_acc = validate(validation_loader, model, loss_fn)\n",
    "\n",
    "        wandb.log({\n",
    "        'epoch': t+1, \n",
    "        #'train_acc': train_acc,\n",
    "        'train_loss': train_loss, \n",
    "        'val_acc': val_acc, \n",
    "        'val_loss': val_loss\n",
    "        })\n",
    "\n",
    "wandb.agent(sweep_id, function=main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a53a840c5da6627cb6dac5001839e6c03fd10e2ff1c4795e5764456eff1405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: xiaosuhu86. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# WANDB_NOTEBOOK_NAME = 'Train_Analysis_VRB_wandb_sweep.ipynb'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 96h6g0gx\n",
      "Sweep URL: https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
    "    'parameters': \n",
    "    {\n",
    "        #'batch_size': {'values': [32, 64]},\n",
    "        #'epochs': {'values': [5,10]},\n",
    "        #'lr': {'values': [0.001, 0.0001]},\n",
    "        'batch_size': {'values': [32]},\n",
    "        'epochs': {'values': [2]},\n",
    "        'lr': {'values': [0.001]},\n",
    "        'model': {'values': ['efficientnet_b0','efficientnet_b2']}\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='VRB-Pytorch-test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNIRS_Dataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.targets = self.img_labels['Label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 4])\n",
    "        image = np.float32(io.loadmat(img_path)['fnirsimg']).reshape(3,21,45)\n",
    "        label = self.img_labels.iloc[idx, 5]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        classifications = torch.argmax(model(X), dim=1)\n",
    "        correct_predictions = sum(classifications==y).item()\n",
    "\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(y)\n",
    "\n",
    "        y_pred.extend(classifications.data.cpu().numpy())\n",
    "        y_true.extend(y.data.cpu().numpy())\n",
    "            \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"val_loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    acc = total_correct/total_instances\n",
    "\n",
    "    # constant for classes\n",
    "    classes = ('No_Pain','Pain')\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "    \n",
    "    TP = df_cm['Pain']['Pain']\n",
    "    TN = df_cm['No_Pain']['No_Pain']\n",
    "\n",
    "    print(f\"val_acc: {acc:>7f} TP: {TP:>4f} TN: {TN:>4f}\")\n",
    "\n",
    "    return loss, acc, TP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: weovikiy with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 2\n",
      "wandb: \tlr: 0.001\n",
      "wandb: \tmodel: efficientnet_b0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MATLAB\\PROJECT_VRB\\Pytorch\\code\\wandb\\run-20230413_185652-weovikiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/weovikiy' target=\"_blank\">sweet-sweep-1</a></strong> to <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/weovikiy' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/weovikiy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.721677  [   32/11536]\n",
      "loss: 0.790990  [ 3232/11536]\n",
      "loss: 1.106159  [ 6432/11536]\n",
      "loss: 1.177879  [ 9632/11536]\n",
      "val_loss: 0.430236  [   32/14420]\n",
      "val_acc: 0.834605 TP: 0.074499 TN: 0.939250\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.733203  [   32/11536]\n",
      "loss: 0.874047  [ 3232/11536]\n",
      "loss: 0.791018  [ 6432/11536]\n",
      "loss: 0.884339  [ 9632/11536]\n",
      "val_loss: 0.782418  [   32/14420]\n",
      "val_acc: 0.492718 TP: 0.601719 TN: 0.477712\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>true_neg</td><td>█▁</td></tr><tr><td>true_pos</td><td>▁█</td></tr><tr><td>val_acc</td><td>█▁</td></tr><tr><td>val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>model</td><td>efficientnet_b0</td></tr><tr><td>train_loss</td><td>0.82395</td></tr><tr><td>true_neg</td><td>0.47771</td></tr><tr><td>true_pos</td><td>0.60172</td></tr><tr><td>val_acc</td><td>0.49272</td></tr><tr><td>val_loss</td><td>0.63717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sweep-1</strong> at: <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/weovikiy' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/weovikiy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_185652-weovikiy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: ouavjsp2 with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 2\n",
      "wandb: \tlr: 0.001\n",
      "wandb: \tmodel: efficientnet_b2\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\MATLAB\\PROJECT_VRB\\Pytorch\\code\\wandb\\run-20230413_185813-ouavjsp2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/ouavjsp2' target=\"_blank\">dutiful-sweep-2</a></strong> to <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/sweeps/96h6g0gx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/ouavjsp2' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/ouavjsp2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.227458  [   32/11536]\n",
      "loss: 1.052659  [ 3232/11536]\n",
      "loss: 0.799534  [ 6432/11536]\n",
      "loss: 0.815652  [ 9632/11536]\n",
      "val_loss: 0.800530  [   32/14420]\n",
      "val_acc: 0.252774 TP: 0.836676 TN: 0.172387\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.979755  [   32/11536]\n",
      "loss: 0.662098  [ 3232/11536]\n",
      "loss: 0.669749  [ 6432/11536]\n",
      "loss: 0.674141  [ 9632/11536]\n",
      "val_loss: 0.460959  [   32/14420]\n",
      "val_acc: 0.825589 TP: 0.060172 TN: 0.930966\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>true_neg</td><td>▁█</td></tr><tr><td>true_pos</td><td>█▁</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>model</td><td>efficientnet_b2</td></tr><tr><td>train_loss</td><td>0.60923</td></tr><tr><td>true_neg</td><td>0.93097</td></tr><tr><td>true_pos</td><td>0.06017</td></tr><tr><td>val_acc</td><td>0.82559</td></tr><tr><td>val_loss</td><td>0.55389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-2</strong> at: <a href='https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/ouavjsp2' target=\"_blank\">https://wandb.ai/xiaosuhu86/VRB-Pytorch-test/runs/ouavjsp2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230413_185813-ouavjsp2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "# Load the data with imbalanced weights\n",
    "train_data=FNIRS_Dataset(\n",
    "    '../Label_VRB.csv',\n",
    "    '../VRBdata/'\n",
    ")\n",
    "\n",
    "total_targets=torch.asarray(train_data.targets)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "    np.arange(len(total_targets)), test_size=0.2, random_state=42, shuffle=True, stratify=total_targets)\n",
    "\n",
    "train_set = torch.utils.data.Subset(train_data, train_idx)\n",
    "# val_set = torch.utils.data.Subset(train_data, valid_idx)\n",
    "\n",
    "train_sample_count = torch.tensor(\n",
    "    [(total_targets[train_idx] == t).sum() for t in torch.unique(total_targets, sorted=True)])\n",
    "train_weight = 1. / train_sample_count.float()\n",
    "train_sample_weight = torch.tensor([train_weight[t] for t in total_targets[train_idx]])\n",
    "\n",
    "#Creating PT data samplers\n",
    "train_sampler = WeightedRandomSampler(train_sample_weight, len(train_sample_weight))\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "def main():\n",
    "    run = wandb.init()\n",
    "\n",
    "    batch_size = wandb.config.batch_size\n",
    "\n",
    "    # Create data loaders:\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
    "                                            sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "    # Model defining\n",
    "    model = timm.create_model(wandb.config.model, num_classes=2, pretrained=False)\n",
    "    model=model.to(device)\n",
    "    \n",
    "    # Other learning parameters\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.lr)\n",
    "    epochs = wandb.config.epochs\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_acc, TP, TN = validate(validation_loader, model, loss_fn)\n",
    "\n",
    "        wandb.log({\n",
    "        'epoch': t+1, \n",
    "        #'train_acc': train_acc,\n",
    "        'train_loss': train_loss, \n",
    "        'val_acc': val_acc, \n",
    "        'val_loss': val_loss,\n",
    "        'true_pos': TP,\n",
    "        'true_neg': TN,\n",
    "        'model': wandb.config.model\n",
    "        })\n",
    "\n",
    "wandb.agent(sweep_id, function=main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a53a840c5da6627cb6dac5001839e6c03fd10e2ff1c4795e5764456eff1405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxiaosuhu86\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# WANDB_NOTEBOOK_NAME = 'Train_Analysis_VRB_wandb_sweep.ipynb'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500 response executing GraphQL.\n",
      "{\"errors\":[{\"message\":\"An internal error occurred. Please contact support.\",\"path\":[\"upsertSweep\"]}],\"data\":{\"upsertSweep\":null}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: knt59wpc\n",
      "Sweep URL: https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/sweeps/knt59wpc\n"
     ]
    }
   ],
   "source": [
    "sweep_configuration = {\n",
    "    'method': 'grid',\n",
    "    'name': 'sweep',\n",
    "    'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
    "    'parameters': \n",
    "    {\n",
    "        'batch_size': {'values': [32, 64]},\n",
    "        'epochs': {'values': [5, 10, 15]},\n",
    "        'lr': {'values': [0.001, 0.0005, 0.0001]},\n",
    "        'model': {'values': ['efficientnet_b0','efficientnet_b2','efficientnet_b4','resnet18d','resnet34d','resnet50d','resnet101d']}\n",
    "     }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project='TMB-Pytorch-test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNIRS_Dataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.targets = self.img_labels['Label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 4])\n",
    "        image = np.float32(io.loadmat(img_path)['fnirsimg']).reshape(3,21,45)\n",
    "        label = self.img_labels.iloc[idx, 5]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validate(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()     # Optional when not using Model Specific layer\n",
    "\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "    y_true=[]\n",
    "    y_pred=[]\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        classifications = torch.argmax(model(X), dim=1)\n",
    "        correct_predictions = sum(classifications==y).item()\n",
    "\n",
    "        total_correct+=correct_predictions\n",
    "        total_instances+=len(y)\n",
    "\n",
    "        y_pred.extend(classifications.data.cpu().numpy())\n",
    "        y_true.extend(y.data.cpu().numpy())\n",
    "            \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"val_loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    acc = total_correct/total_instances\n",
    "\n",
    "    # constant for classes\n",
    "    classes = ('No_Pain','Pain')\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "    \n",
    "    TP = df_cm['Pain']['Pain']\n",
    "    TN = df_cm['No_Pain']['No_Pain']\n",
    "\n",
    "    print(f\"val_acc: {acc:>7f} TP: {TP:>4f} TN: {TN:>4f}\")\n",
    "\n",
    "    return loss, acc, TP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a7dotcmd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: efficientnet_b0\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Python\\Pytorch\\Code\\wandb\\run-20230417_154520-a7dotcmd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/runs/a7dotcmd' target=\"_blank\">rural-sweep-1</a></strong> to <a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/sweeps/knt59wpc' target=\"_blank\">https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/sweeps/knt59wpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test' target=\"_blank\">https://wandb.ai/xiaosuhu86/TMB-Pytorch-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/sweeps/knt59wpc' target=\"_blank\">https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/sweeps/knt59wpc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/runs/a7dotcmd' target=\"_blank\">https://wandb.ai/xiaosuhu86/TMB-Pytorch-test/runs/a7dotcmd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.761942  [   32/12182]\n",
      "loss: 1.170739  [ 3232/12182]\n",
      "loss: 1.129218  [ 6432/12182]\n",
      "loss: 0.848713  [ 9632/12182]\n",
      "val_loss: 1.414662  [   32/15228]\n",
      "val_acc: 0.771832 TP: 0.159686 TN: 0.859610\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.819852  [   32/12182]\n",
      "loss: 0.764893  [ 3232/12182]\n",
      "loss: 0.764489  [ 6432/12182]\n",
      "loss: 0.712384  [ 9632/12182]\n",
      "val_loss: 1.128606  [   32/15228]\n",
      "val_acc: 0.814183 TP: 0.081152 TN: 0.919294\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.667757  [   32/12182]\n",
      "loss: 0.680704  [ 3232/12182]\n",
      "loss: 0.615587  [ 6432/12182]\n",
      "loss: 0.480297  [ 9632/12182]\n",
      "val_loss: 2.546973  [   32/15228]\n",
      "val_acc: 0.677938 TP: 0.340314 TN: 0.726351\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.569769  [   32/12182]\n",
      "loss: 0.543710  [ 3232/12182]\n",
      "loss: 0.664078  [ 6432/12182]\n",
      "loss: 0.406911  [ 9632/12182]\n",
      "val_loss: 0.778536  [   32/15228]\n"
     ]
    }
   ],
   "source": [
    "# Load the data with imbalanced weights\n",
    "train_data=FNIRS_Dataset(\n",
    "    '../Label_TMB.csv',\n",
    "    '../TMBdata/'\n",
    ")\n",
    "\n",
    "total_targets=torch.asarray(train_data.targets)\n",
    "train_idx, valid_idx= train_test_split(\n",
    "    np.arange(len(total_targets)), test_size=0.2, random_state=42, shuffle=True, stratify=total_targets)\n",
    "\n",
    "train_set = torch.utils.data.Subset(train_data, train_idx)\n",
    "# val_set = torch.utils.data.Subset(train_data, valid_idx)\n",
    "\n",
    "train_sample_count = torch.tensor(\n",
    "    [(total_targets[train_idx] == t).sum() for t in torch.unique(total_targets, sorted=True)])\n",
    "train_weight = 1. / train_sample_count.float()\n",
    "train_sample_weight = torch.tensor([train_weight[t] for t in total_targets[train_idx]])\n",
    "\n",
    "#Creating PT data samplers\n",
    "train_sampler = WeightedRandomSampler(train_sample_weight, len(train_sample_weight))\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "def main():\n",
    "    run = wandb.init()\n",
    "\n",
    "    batch_size = wandb.config.batch_size\n",
    "\n",
    "    # Create data loaders:\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
    "                                            sampler=train_sampler)\n",
    "    validation_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "                                                    sampler=valid_sampler)\n",
    "\n",
    "    # Model defining\n",
    "    model = timm.create_model(wandb.config.model, num_classes=2, pretrained=False)\n",
    "    model=model.to(device)\n",
    "    \n",
    "    # Other learning parameters\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.lr)\n",
    "    epochs = wandb.config.epochs\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_acc, TP, TN = validate(validation_loader, model, loss_fn)\n",
    "\n",
    "        wandb.log({\n",
    "        'epoch': t+1, \n",
    "        #'train_acc': train_acc,\n",
    "        'train_loss': train_loss, \n",
    "        'val_acc': val_acc, \n",
    "        'val_loss': val_loss,\n",
    "        'true_pos': TP,\n",
    "        'true_neg': TN,\n",
    "        'model': wandb.config.model\n",
    "        })\n",
    "\n",
    "wandb.agent(sweep_id, function=main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52a53a840c5da6627cb6dac5001839e6c03fd10e2ff1c4795e5764456eff1405"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
